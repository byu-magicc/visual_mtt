#!/usr/bin/env python
PACKAGE = "visual_mtt"

from dynamic_reconfigure.parameter_generator_catkin import *

gen = ParameterGenerator()

# INSTRUCTIONS
# Don't use this to set default values. Use yaml files, loaded in launch files.
# This cfg specifies which params are dynamically reconfigurable along with
# bounds. The reconfigure callback needs to recieve these and assign them to
# overwrite the class members.

# entries decoded:
# group.add("strict_param_name", type, level, "Mouseover Description", default, min, max)

# general processing
general = gen.add_group("General Processing")
general.add("frame_stride", int_t, 0, "Process Every Nth Frame", 0, 1, 10)
general.add("downsize_scale", double_t, 0, "SD Image Scale", 0, 0.1, 1)
general.add("published_video_scale", double_t, 0, "Scale of output video topic", 0, 0.1, 1)
general.add("text_scale", double_t, 0, "Scale of text on output image", 0, 0, 10)

# feature manager
feature_manager = gen.add_group("Feature Manager")
type_enum = gen.enum([ gen.const("KLT_Tracker",             int_t, 0, ""),
                       gen.const("ORB_Brute_Force_Matcher", int_t, 1, "")], "")
feature_manager.add("feature_type", int_t, 0, "Feature Type Used for Point Correspondences", 0, edit_method=type_enum)
feature_manager.add("points_max", int_t, 0, "Maximum Number of Features to Pair", 0, 0, 10000)

# feature motion
feature_motion = gen.add_group("Feature Motion")
feature_motion.add("feature_motion_enabled", bool_t, 0, "Enable or Disable the Feature Motion Source", False)
feature_motion.add("feature_motion_sigmaR_pos", double_t, 0, "Measurement Covariance for position data", 0, 0, 0.05)
feature_motion.add("feature_motion_sigmaR_vel", double_t, 0, "Measurement Covariance for velocity data", 0, 0, 0.05)
feature_motion.add("minimum_feature_velocity", double_t, 0, "Minimum Feature Velocity", 0, 0, 0.2)
feature_motion.add("maximum_feature_velocity", double_t, 0, "Maximum Feature Velocity", 0, 0, 0.3)

# difference image
difference_image = gen.add_group("Difference Image")
difference_image.add("difference_image_enabled", bool_t, 0, "Enable or Disable the Difference Image Source", False)
difference_image.add("difference_extra_plots", bool_t, 0, "Helpful Introspective Plots", False)
difference_image.add("difference_image_sigmaR_pos", double_t, 0, "Measurement Covariance for position data", 0, 0, 0.3)
difference_image.add("blur_kernel", int_t, 0, "Blur Kernel Size", 0, 0, 50)
difference_image.add("blur_sigma", double_t, 0, "Smoothing Standard Deviation", 0, 0, 20)
difference_image.add("threshold", double_t, 0, "Difference Threshold", 0, 0, 255)
difference_image.add("morph_size", int_t, 0, "Morphology Element Size", 0, 0, 20)
difference_image.add("morph_iterations", int_t, 0, "Morphology Iterations", 0, 1, 5)
difference_image.add("min_complexity", int_t, 0, "Minimum Difference Complexity", 0, 0, 100)
difference_image.add("max_complexity", int_t, 0, "Maximum Difference Complexity", 0, 0, 100)

# recognition manager
recognition_manager = gen.add_group("Target Recognition Manager")
rec_type_enum = gen.enum([ gen.const("None",                int_t, 0, ""),
                           gen.const("Template_Matching",   int_t, 1, ""),
                           gen.const("Visual_Bag_of_Words", int_t, 2, "")], "")
recognition_manager.add("recognition_type", int_t, 0, "Recognition Type Used for Track Reacquisition", 0, edit_method=rec_type_enum)
recognition_manager.add("crop_width", int_t, 0, "Cropped Subimage Width Used for Recognition", 0, 1, 200)


exit(gen.generate(PACKAGE, "visual_frontend", "visual_frontend"))